{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.docx import partition_docx\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from graphrag_sdk.source import Source\n",
    "from falkordb import FalkorDB\n",
    "from graphrag_sdk import KnowledgeGraph, Ontology\n",
    "from graphrag_sdk.models.openai import OpenAiGenerativeModel\n",
    "from graphrag_sdk.model_config import (\n",
    "    KnowledgeGraphModelConfig,\n",
    ")  # Import the missing config\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = (\n",
    "    \"Your_OpenAi_Keys\"\n",
    ")\n",
    "# Specify directories containing the files\n",
    "pdf_directory = \"Data/PDFS\"\n",
    "docx_directory = \"Data/DOCX\"\n",
    "pptx_directory = \"Data/PPTX\"\n",
    "\n",
    "\n",
    "pdf_sources = []\n",
    "\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_directory, filename)\n",
    "        elements = partition_pdf(filename=pdf_path)\n",
    "\n",
    "        # Save extracted text to .txt file\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_path = os.path.join(pdf_directory, txt_filename)\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            for element in elements:\n",
    "                if element.text:\n",
    "                    txt_file.write(element.text + \"\\n\")\n",
    "\n",
    "        pdf_sources.append(Source(txt_path))\n",
    "\n",
    "print(\"PDF text extraction complete.\")\n",
    "docx_sources = []\n",
    "\n",
    "for filename in os.listdir(docx_directory):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        docx_path = os.path.join(docx_directory, filename)\n",
    "        elements = partition_docx(filename=docx_path)\n",
    "\n",
    "        # Save extracted text to .txt file\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_path = os.path.join(docx_directory, txt_filename)\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            for element in elements:\n",
    "                if element.text:\n",
    "                    txt_file.write(element.text + \"\\n\")\n",
    "\n",
    "        docx_sources.append(Source(txt_path))\n",
    "\n",
    "print(\"DOCX text extraction complete.\")\n",
    "\n",
    "\n",
    "pptx_sources = []\n",
    "\n",
    "for filename in os.listdir(pptx_directory):\n",
    "    if filename.endswith(\".pptx\"):\n",
    "        pptx_path = os.path.join(pptx_directory, filename)\n",
    "        elements = partition_pptx(filename=pptx_path)\n",
    "\n",
    "        # Save extracted text to .txt file\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_path = os.path.join(pptx_directory, txt_filename)\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            for element in elements:\n",
    "                if element.text:\n",
    "                    txt_file.write(element.text + \"\\n\")\n",
    "\n",
    "        pptx_sources.append(Source(txt_path))\n",
    "\n",
    "print(\"PPTX text extraction complete.\")\n",
    "\n",
    "\n",
    "# Define the model to be used for the ontology\n",
    "model = OpenAiGenerativeModel(model_name=\"gpt-4o\")\n",
    "\n",
    "# Combine all sources for ontology generation\n",
    "all_sources = pdf_sources + docx_sources + pptx_sources\n",
    "\n",
    "\n",
    "ontology = Ontology.from_sources(\n",
    "    sources=all_sources,\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "\n",
    "# Knowledge Graph\n",
    "kg = KnowledgeGraph(\n",
    "    name=\"K_G_A\",\n",
    "    model_config=KnowledgeGraphModelConfig.with_model(model),\n",
    "    ontology=ontology,\n",
    "    host=\" your Host \",\n",
    "    username=\"username\",\n",
    "    password=\"password\",\n",
    "    port=\"port_number\",\n",
    ")\n",
    "\n",
    "# Process the sources to create the graph\n",
    "kg.process_sources(all_sources)\n",
    "\n",
    "# Test the connection\n",
    "print(\"Knowledge Graph created:\")\n",
    "print(kg._name)\n",
    "print(kg.db.list_graphs())\n",
    "\n",
    "\n",
    "\n",
    "# Conversation.\n",
    "chat = kg.chat_session()\n",
    "response = chat.send_message(\"Enter your question Based on Data.\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k_g_a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
